## 目录

## 摘要（翻译）
蚊媒疾病在全球范围内对人类健康构成重大威胁。传统的蚊子物种鉴定形态学和分子生物学方法通常需要专业知识或昂贵的实验室设备。然而，基于深度学习方法（尤其是卷积神经网络，CNNs）的图像式蚊子物种鉴定正逐渐成为一种潜在的替代方案。本研究评估了深度学习方法（特别是卷积神经网络）在蚊子物种分类中的有效性，并对比了躯体图像和翅膀图像的分类性能。研究使用了 3184 个样本，涉及四种形态相似的伊蚊物种（埃及伊蚊、白纹伊蚊、朝鲜伊蚊和日本伊蚊）。数据集按 70% 训练集、15% 验证集和 15% 测试集的比例划分。研究中使用的深度学习模型包括 ResNet50、MobileNetV2、EfficientNetV2、DenseNet、CNN 以及混合模型（CNN + MobileNetV2）。独立的 MobileNetV2 模型在翅膀图像分类中取得了最高准确率（93.3%），而本文提出的混合模型（CNN + MobileNetV2）在躯体图像分类中表现最佳（79.6%）。这些结果不仅显示出高预测准确率，还在各项评估指标中体现出较强的类别区分能力和稳健性。虽然这些发现证明了两种分类方法的潜力，但也凸显了在开发实用且易获取的分类系统时面临的一些实施挑战。研究结果表明，轻量型和混合深度学习架构可作为开发规模化蚊子媒介监测系统的可靠替代方案。


## 摘要（解读）
摘要高度凝练了研究的核心要素：首先点明研究背景 —— 传统蚊子分类方法的局限性，引出深度学习的应用潜力；明确研究对象（四种形态相似伊蚊）、数据集规模及划分方式；详细列出所用模型及关键结果（MobileNetV2 适配翅膀图像，混合模型适配躯体图像）；最后总结研究价值与应用方向。核心创新点在于**系统对比躯体与翅膀图像的分类效果，并提出针对性的混合模型**，解决了传统方法“专业依赖”和“成本高”的痛点，为规模化监测提供了技术支撑。


## 1.引言（翻译）

蚊媒疾病是热带和亚热带地区最严重的公共卫生威胁之一。全球变暖、森林砍伐、快速城市化和国际贸易增长等大规模环境变化，使得埃及伊蚊和白纹伊蚊等媒介物种能够扩散到此前未受影响的地区。这种扩散不仅加速了病原体的传播，还增加了此前无暴露史或无免疫力人群的感染风险 [23]。世界卫生组织报告称，登革热是伊蚊传播的最常见病毒感染病，威胁着近 40 亿人，每年约有 1 亿例症状性病例和 4 万例死亡。其他蚊媒疾病包括基孔肯雅热、寨卡病毒病、黄热病、西尼罗河热、日本脑炎、疟疾和淋巴丝虫病 [4,14]。

蚊子媒介的准确物种级鉴定对于有效的监测、疫情预测和针对性防控策略至关重要。伊蚊属、按蚊属和库蚊属等不同蚊子属传播不同的病毒和寄生虫病原体（表 1），鉴定错误可能导致防控措施失效。聚合酶链式反应（PCR）等分子技术虽能实现高准确率，但成本高昂、耗时费力，且需要专业实验室设施，不适合大规模或资源有限的场景部署 [16]。

如表 1 所示，伊蚊属、按蚊属和库蚊属蚊子负责传播多种疾病。每个物种都是一系列病毒和寄生虫病原体的传播媒介，凸显了它们在全球公共卫生中的重要作用 [14]。

人工智能（AI）领域的最新进展，尤其是卷积神经网络（CNNs）等深度学习（DL）方法，已实现基于图像的昆虫自动分类，并达到较高准确率 [3,17,24]。这些方法减少了对专业分类学家的依赖，能够快速分类，且可集成到便携式或移动设备中用于野外作业。然而，现有模型存在重要局限性：

- 大多数模型在受控实验室环境中训练和验证，限制了其在多变现实环境中的性能；
- 通常依赖蚊子完整躯体图像，对翅膀等其他形态特征关注较少；
- 图像来源变异（不同设备、光照条件）对模型性能的影响常被忽视。

对翅膀图像的关注不足值得重视，因为蚊子翅膀具有物种特异性的脉序和形状 —— 与完整躯体图像相比，这些特征可能更稳定、更具区分度，尤其是在野外采集样本中躯体受损、不完整或被遮挡的情况下。因此，将翅膀作为主要鉴定特征进行评估，可能开发出更稳健、更实用的监测工具。

已有研究表明，翅膀形态比躯体图像更适合作为分类依据 [15,17]。因此，本研究的创新点并非简单验证这一发现，而是探索**架构效率**：具体研究轻量型模型（如 MobileNetV2）和新型混合架构（CNN-MobileNetV2）是否能在该特定数据集上实现稳健分类，为标准深层模型提供计算成本更低的替代方案。

本研究通过以下方式填补现有研究空白：

（i）使用多种 CNN 架构系统对比躯体和翅膀图像的分类性能；

（ii）提出针对该数据集优化的轻量型混合模型（CNN + MobileNetV2）。

## 引言（解读）
引言遵循“背景→问题→现有方案局限→研究目标”的逻辑展开：

1. 以蚊媒疾病的公共卫生威胁切入，用 WHO 权威数据（登革热影响范围、死亡人数）强化研究必要性，同时提及环境变化对蚊子扩散的推动作用，说明分类监测的紧迫性；
2. 强调“准确物种鉴定”与“防控效果”的直接关联，对比分子技术（PCR）的优缺点，引出“低成本、高效分类方法”的需求；
3. 梳理深度学习在昆虫分类中的应用现状，精准指出现有模型的三大核心缺口（环境适应性差、忽视翅膀特征、忽视图像来源变异），为研究定位；
4. 解释翅膀图像的生物学优势（物种特异性脉序、抗躯体损伤），明确本研究与前人的差异 —— 不重复验证翅膀图像的有效性，而是聚焦“模型架构优化”，追求“性能与计算效率的平衡”；
5. 最终明确两大研究任务，为后续实验设计划定范围，逻辑连贯且目标清晰。

## 2.相关工作（翻译）
表2总结了基于深度学习的蚊子物种分类系统相关文献，按所用方法、数据集细节和实验结果进行整理。此外，这些研究还根据数据集类型（如翅膀图像、躯体图像或混合数据集）进行了分类。

表1 伊蚊属、按蚊属和库蚊属蚊子传播的疾病，凸显其作为多种病毒和寄生虫病原体传播媒介的作用 [14]

| 媒介（属） | 疾病         | 病原类型 |
|------------|--------------|----------|
| 伊蚊属     | 基孔肯雅热   | 病毒     |
|            | 登革热       | 病毒     |
|            | 淋巴丝虫病   | 寄生虫   |
|            | 裂谷热       | 病毒     |
|            | 黄热病       | 病毒     |
|            | 寨卡病毒病   | 病毒     |
| 按蚊属     | 淋巴丝虫病   | 寄生虫   |
|            | 疟疾         | 寄生虫   |
|            | 奥尼翁翁病毒病 | 病毒     |
| 库蚊属     | 日本脑炎     | 病毒     |
|            | 淋巴丝虫病   | 寄生虫   |
|            | 西尼罗热     | 病毒     |


表 2 2020-2024年基于深度学习的蚊子分类相关文献总结，详细列出方法、数据集和关键性能结果

| 作者           | 方法                          | 数据集                          | 性能                          |
|----------------|-------------------------------|---------------------------------|-------------------------------|
| Nolte 等人 [15] | CNN                           | 796 张图像（4 种伊蚊）| 翅膀：87.6%，躯体：78.9%      |
| Araújo 等人 [2] | AlexNet                       | 1343 张图像（4 种）| 准确率 94%                    |
| Johnson 等人 [9]| Mask R-CNN                    | 20 张图像（微观和宏观）| 微观：98.88%，宏观：96.06%    |
| Wang 等人 [21]  | Faster R-CNN                  | 1729 张图像（野外样本）| F1 分数：97.7%                |
| Wang 和 Patel [22] | CNN + RIFS                | 2000 张图像（2 种）| 准确率 98.6%                  |
| Montalbo[13]   | SqueezeNet                    | 3578 张图像                     | 准确率 99.22%                 |
| Gupta 等人 [5]  | CNN                           | 1000 + 张图像                   | 宏观平均召回率 94.4%          |
| Minakshi 等人 [12] | Inception-ResNet V2        | 25867 张图像（250 个样本）| 准确率 80%                    |
| Adhane 等人 [1]  | CNN（迁移学习 + Grad-CAM）| Mosquito Alert 数据集           | 准确率 94%                    |
| Karim 等人 [10]  | Swin-B                        | 5000 张图像（10 种）| 准确率 99.6%                  |


该领域的近期研究表明，卷积神经网络（CNNs）在蚊子物种分类项目中取得了良好效果。Sauer等人证明，CNNs 能够利用躯体和翅膀图像成功区分四种形态相似的伊蚊物种；翅膀数据的准确率为87.6%，躯体数据的准确率为78.9%[17]，其他研究则侧重于通过调整模型以提升性能，例如，He 等人利用深度残差网络（ResNet）结构改进图像识别，为多种蚊子分类系统奠定了基础 [6]。Howard 等人开发了 MobileNet——一种轻量级架构，专为更便携的蚊子分类项目设计，在保证可接受准确率的同时实现了高效计算 [7]。此外，Tan 等人提出的 EfficientNet 等先进架构，用于改进模型缩放并提升准确率 [19]。Huang 等人开发的 DenseNet 架构，即使在现有有限的情况下，也能实现特征连接并增强分类性能 [8]。MobileNetV1 和 DenseNet 等轻量级模型在降低计算负载的同时，展现出具有竞争力的准确率 [7,8]。此外，利用预训练模型的迁移学习技术也取得了显著进展。Singh 等人[18]等研究在预训练 CNN 模型上应用迁移学习进行植物物种分类，并提出类似的迁移学习方法也可有效应用于蚊子物种分类。Gupta 等人 [5] 使用基于 CNN 的 IDX 算法进行蚊子物种分类验证，对来自美国东南部和巴布亚新几内亚的数据集分别实现了 80.2% 和 94.4% 的宏观平均召回率。大规模数据集也得到了应用，例如 Minakshi 等人 [12] 将研究使用 Inception-ResNet V2 架构对 25667 张蚊子图像进行了分类，准确率达到 80%。Adhane 等人 [1] 的预训练模型网络应用于白纹伊蚊分类，准确验证了预训练模型在蚊子图像数据集上的潜力。Karim 等人 [10] 展示的 Swin Transformer 等前沿方法表明，基于视觉 Transformer 的模型能够实现高达 99.6% 的蚊子分类准确率，而 MobileViT 等轻量级模型也达到了 98.9% 的较高准确率。这些研究共同凸显了深度学习在近乎完美分类（尤其是预训练模型）方面的显著进展。此外，轻量级架构、迁移学习方法和创新的 Transformer-based 模型的结合，体现了现实应用的必要性。这些研究共同证明了深度学习结合视觉数据在蚊子物种分类领域取得的显著成就。


尽管取得了这些进展，现有文献仍存在若干关键局限性：大多数研究要么仅关注完整躯体图像，要么涉及较少物种或受控环境下的简单分类任务；直接对比躯体图像与翅膀图像在形态相似伊蚊物种分类中性能的研究较少；此外，探索结合轻量级网络和特征丰富网络优势以实现平衡性能的混合模型架构的研究也不多见。


本研究旨在填补这些空白。通过使用多种深度学习模型（包括新型混合架构 CNN-MobileNetV2）系统对比躯体和翅膀图像的分类性能，研究证明，翅膀图像能产生更优的分类结果，且混合模型可在不牺牲效率的前提下显著提升性能，为自动化媒介监测系统提供了实用且可扩展的方法 —— 尤其是在计算资源有限的野外应用场景中。


## 解读
相关工作部分通过“表格梳理 + 文献评述”的方式，清晰呈现领域研究现状：

1. 表1直观展示蚊子分类与疾病防控的关联，强化“准确分类”的实际意义；表2系统梳理近5年关键研究，从方法、数据集、性能三个维度对比，便于读者快速定位本研究的位置；
2. 文献评述分层展开：先肯定 CNN、ResNet、MobileNet 等主流模型的应用成果，再介绍迁移学习、大规模数据集、Transformer 等前沿技术的进展，最后精准指出现有研究的三大缺口 —— 忽视躯体与翅膀图像的直接对比、缺乏对形态相似物种的研究、混合模型探索不足；
3. 本研究的定位明确：不是重复已有研究，而是针对“形态相似伊蚊”这一更具挑战性的场景，聚焦“躯体 vs 翅膀图像”的系统对比和“混合模型”的创新设计，填补领域空白，同时强调研究的“实用导向”（适配野外计算资源有限的场景）。

## 3. 材料与方法

**翻译**
如图1所示，本研究的整体流程包括四个主要阶段：图像采集与数据集制备、针对蚊子形态的预处理、多种架构模型训练（特征提取、分类）和基于生物学相关性能指标的评估。通过在预处理和训练过程中明确融入翅膀脉序、腿部条纹和盾片标记等形态特征，本研究的方法既符合传统昆虫学鉴定方法，又充分利用了深度学习模型的可扩展性。


<!-- 插入图1，图注自动显示在图片下方 -->
![图1 本研究的整体流程框架](images/fig1_method_flow.png)

图1. 研究整体流程图，展示从躯体和翅膀图像预处理到模型训练（特征提取、分类）及最终性能评估的全流程


## 3.1 数据集
本研究使用 Nolte 等人 [15] 发布的公开图像数据集，该数据集可在 Dryad 数字仓库获取（https://doi.org/10.5061/dryad.b8gbt7mx）。选择该数据集的原因是其高分辨率和标准化特性，这对有效训练深度学习模型至关重要。

最终数据集共包含 3184 张图像，涉及四种蚊子物种：埃及伊蚊（AE）、白纹伊蚊（AL）、日本伊蚊（JA）和朝鲜伊蚊（KO）。为避免训练过程中的类别不平衡问题，数据分布均匀，每个物种各 796 张图像。

每个物种的图像分为两类形态特征：
- 躯体图像：398 张/物种（总计 1592 张）；
- 翅膀图像：398 张/物种（总计 1592 张）。

关于样本来源：埃及伊蚊图像来自美国佛罗里达群岛的野外采集；其他物种（白纹伊蚊、日本伊蚊、朝鲜伊蚊）来自欧洲的实验室种群和监测项目（详见原始数据集说明）。所有照片均在受控实验室环境下使用立体显微镜拍摄，以保证光照和背景的一致性。


## 3.2 预处理
预处理阶段，所有图像均调整为适配各架构输入要求的尺寸（ResNet/DenseNet 为 224×224，EfficientNet 为 300×300，MobileNetV2 和自定义 CNN 为 384×384）。为提升模型在多变异条件下的泛化能力，同时保留形态完整性，本研究应用了数据增强技术，包括：
- 随机旋转（±15°，模拟样本朝向变化）；
- 随机缩放（±10%，对应放大倍数差异）；
- 水平/垂直翻转（模拟镜像拍摄）；
- 随机平移（±10%，模拟偏心成像）。

像素强度值归一化至 0-1 范围，以保证数据集间对比度一致。为解决类别不平衡问题，训练过程中应用了类别权重，确保少数类别在模型学习中不被低估。

该增强流程通过 TensorFlow 的 ImageDataGenerator 在训练过程中动态应用。所有模型使用相同的增强参数以保证对比的公平性，仅根据各架构的输入要求调整最终目标尺寸（如 224×224、384×384）。


## 3.3 深度学习模型
所有模型均基于 TensorFlow 2.15 实现，在配备 24GB 显存的 NVIDIA RTX 4090 GPU 上训练。优化器采用 Adam，初始学习率为 \(1 \times 10^{-3}\)，采用余弦衰减调度策略。损失函数使用类别交叉熵，批次大小为 32，训练轮次为 100 轮；基于验证损失采用早停策略（patience=10）以防止过拟合。迁移学习模型使用 ImageNet 预训练权重，初始收敛后解冻最后 20%-30% 的卷积层进行微调，以适配蚊子特有的形态特征。

本研究评估了四种预训练架构（ResNet50、MobileNetV2、EfficientNetB0、DenseNet121）和一种自定义 CNN。自定义 CNN 专为蚊子分类设计，处理 384×384 输入图像，通过三个卷积块（64、128、256 个过滤器；3×3 核），每个卷积块后接批量归一化、ReLU 激活和最大池化，扁平化特征经 256 神经元全连接层（0.3 Dropout）后，输入 Softmax 输出层。该设计聚焦于捕捉与分类鉴定最相关的中等级别纹理和脉序特征。


### 3.3.1 ResNet
ResNet 模型处理 224×224 像素的图像，架构起始为 3×3 窗口的最大池化。第一个卷积层使用 64 个过滤器（7×7）进行初始特征提取，之后输出传递至一系列卷积块。例如，第二层混合使用 64 个（1×1 和 3×3）和 256 个（1×1）过滤器；第三、四、五层延续这一模式，过滤器数量逐步增加至 128/512、256/1024，最终达到 512/2048。这种分层设计使网络能够学习日益复杂的特征。除第一层外，所有 3×3 过滤器的卷积步长均为 [1,1]，采用 “same” 填充以保持空间维度 [6]。


### 3.3.2 MobileNet
MobileNet 专为计算资源有限的环境（如移动设备）设计，注重效率。其处理 384×384 像素的输入图像，速度优势源于深度可分离卷积技术 —— 将标准卷积拆分为两个独立更快捷的步骤。流程起始为 32 个过滤器的传统 3×3 卷积，之后依赖其标志性的深度可分离卷积，再通过 1×1 逐点卷积融合学习到的特征。每层过滤器数量逐步增加（64、128 等），使模型在无需标准 CNN 高额计算成本的情况下构建特征理解。架构最终通过全局平均池化层和全连接层输出分类结果 [7]。


### 3.3.3 EfficientNet
EfficientNet 在平衡高准确率和低计算成本，核心创新是“复合缩放”方法 —— 系统地、均衡地缩放模型的深度、宽度和输入分辨率（通常为 300×300 像素）。基础模型为 EfficientNetB0，在此基础上进行缩放。与 MobileNet 类似，其采用深度可分离卷积降低运算量，起始为 32 个过滤器并逐步增加。这种智能缩放使模型在无需大量硬件资源的情况下实现卓越性能 [19]。


### 3.3.4 DenseNet
密集连接卷积网络（DenseNet）的核心原则是改善网络中信息和梯度的流动，通过将每层直接连接至所有后续层实现这一目标。对于 224×224 输入图像，所有前序层的特征图将被拼接并输入当前层，这一设计鼓励特征复用，形成更紧凑、高效的模型。网络起始为 64 个过滤器，后续层过滤器数量逐步增加（128、256 等）。这种密集连接有助于模型以更少的参数实现高准确率 [8]。


### 3.3.5 卷积神经网络（CNNs）
卷积神经网络（CNNs）是大多数基于图像的深度学习任务的标准架构，专为处理像素网格类数据设计。典型 CNN 处理 384×384 像素输入，通过一系列层对图像进行处理：初始卷积层使用少量过滤器（如 3×3 或 5×5）捕捉边缘或纹理等简单特征；随着数据向网络深层传递，过滤器逐渐学习识别更抽象、复杂的模式。

层间采用池化操作（如最大池化）缩小空间维度，提炼关键信息并降低计算负载。网络最终通过全连接层对高级特征进行处理，输出最终预测结果。
